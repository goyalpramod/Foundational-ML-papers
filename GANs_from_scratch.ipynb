{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM01WMaF2stTORXp66fvVCq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goyalpramod/paper_implementations/blob/main/GANs_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code implementation of the following paper -> [Generative Adversarial Nets](https://arxiv.org/pdf/1406.2661)"
      ],
      "metadata": {
        "id": "zFJfdDNtNGMd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This work has been highly influenced by the following implemnetations\n",
        "\n",
        "* [bamos/dcgan-completion.tensorflow](https://github.com/bamos/dcgan-completion.tensorflow)\n",
        "* [soumith/dcgan.torch](https://github.com/soumith/dcgan.torch/blob/master/main.lua) [The original pytorch implementation, you can find the tf version in alec's github]\n",
        "* [openai/improved-gan](https://github.com/openai/improved-gan)\n",
        "* [lilianweng/unified-gan-tensorflow](https://github.dev/lilianweng/unified-gan-tensorflow) [I picked this one to follow (no reasons)]\n",
        "* [carpedm20/DCGAN-tensorflow](https://github.com/carpedm20/DCGAN-tensorflow) [Most of the implementation build on this]"
      ],
      "metadata": {
        "id": "zalcj3iZNkOp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also check out the following blogs for more clarity on the topic\n",
        "* [Brandon's Blog](https://bamos.github.io/2016/08/09/deep-completion/)\n",
        "* [Lil'log's Blog](https://lilianweng.github.io/posts/2017-08-20-gan/)"
      ],
      "metadata": {
        "id": "R9NfTmncOO4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lets understand some equations from the paper\n",
        "\n",
        "$\\min_G \\max_D V(D,G) = \\mathbb{E}_{x\\sim p_{data}(x)}[\\log D(x)] + \\mathbb{E}_{z\\sim p_z(z)}[\\log(1-D(G(z)))]$"
      ],
      "metadata": {
        "id": "SOlZwZzuOrqA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\min_G \\max_D V(D,G)$\n",
        "\n",
        "This notation means:\n",
        "\n",
        "* The discriminator D tries to maximize V(D,G)\n",
        "* The generator G tries to minimize V(D,G)\n",
        "\n",
        "This creates an adversarial game between G and D"
      ],
      "metadata": {
        "id": "0LV-R9OoOrmf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\mathbb{E}_{x\\sim p_{data}(x)}[\\log D(x)]$\n",
        "\n",
        "This represents:\n",
        "* Expected value (𝔼) over samples x drawn from the real data distribution pdata(x)\n",
        "* D(x) outputs a probability between 0 and 1 (how \"real\" D thinks x is)\n",
        "* log D(x) rewards D for correctly identifying real samples\n",
        "* When D(x)→1 for real data, log D(x)→0, maximizing the objective"
      ],
      "metadata": {
        "id": "7S88JELwQC0G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\mathbb{E}_{z\\sim p_z(z)}[\\log(1-D(G(z)))]$\n",
        "\n",
        "This represents:\n",
        "\n",
        "* Expected value over random noise z drawn from noise distribution pz(z)\n",
        "* G(z) generates fake samples from noise\n",
        "* D(G(z)) is the discriminator's output on generated samples\n",
        "* log(1-D(G(z))) rewards D for correctly identifying fake samples\n",
        "* When D(G(z))→0 for fake data, log(1-D(G(z)))→0, maximizing the objective"
      ],
      "metadata": {
        "id": "uw3n64oYQCxz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$D^*_G(x) = \\frac{p_{data}(x)}{p_{data}(x) + p_g(x)}$"
      ],
      "metadata": {
        "id": "pGdzJxJ4QCvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "g_s0aCsWQBVl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn.ConvTranspose2d?"
      ],
      "metadata": {
        "id": "xmsOFEfWc7qx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    \"\"\"\n",
        "    Input: (batch_size, latent_dim)  # typically latent_dim = 100\n",
        "    Output: (batch_size, channels, height, width)  # e.g., (batch_size, 3, 64, 64)\n",
        "\n",
        "    Architecture Hints:\n",
        "    1. Start with Dense layer to reshape latent vector\n",
        "    2. Use multiple ConvTranspose2d layers to upscale\n",
        "    3. Each layer should follow pattern: ConvTranspose2d -> BatchNorm2d -> ReLU\n",
        "    4. Final layer should use Tanh activation\n",
        "    \"\"\"\n",
        "    def __init__(self, latent_dim):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # Step 1: Dense layer to reshape\n",
        "        # latent_dim -> (4*4*512) features\n",
        "        # Hint: Use Linear layer here\n",
        "\n",
        "        # Step 2: Reshape to (batch_size, 512, 4, 4)\n",
        "\n",
        "        # Step 3: Multiple ConvTranspose2d blocks\n",
        "        # Block 1: (512, 4, 4) -> (256, 8, 8)\n",
        "        # kernel_size=4, stride=2, padding=1\n",
        "\n",
        "        # Block 2: (256, 8, 8) -> (128, 16, 16)\n",
        "        # Same parameters as above\n",
        "\n",
        "        # Block 3: (128, 16, 16) -> (64, 32, 32)\n",
        "\n",
        "        # Final Block: (64, 32, 32) -> (3, 64, 64)\n",
        "        # Don't forget Tanh() at the end!"
      ],
      "metadata": {
        "id": "wokUPP0MaIUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        # Dense layer\n",
        "        self.linear = nn.Linear(latent_dim, 4*4*512)\n",
        "\n",
        "        # Blocks\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.block4 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, latent_dim)\n",
        "        x = self.linear(x)\n",
        "        x = x.view(-1, 512, 4, 4)  # reshape using view\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "RA5foquLfJGN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn.Conv2d?"
      ],
      "metadata": {
        "id": "XV3E6bYIiSBo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    \"\"\"\n",
        "    Input: (batch_size, channels, height, width)  # e.g., (batch_size, 3, 64, 64)\n",
        "    Output: (batch_size, 1)  # probability between 0-1\n",
        "\n",
        "    Architecture Hints:\n",
        "    1. Use Conv2d layers to downsample\n",
        "    2. Each layer: Conv2d -> BatchNorm2d (except first) -> LeakyReLU\n",
        "    3. Final layer should be Dense with Sigmoid\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # Block 1: (3, 64, 64) -> (64, 32, 32)\n",
        "        # Conv2d: kernel_size=4, stride=2, padding=1\n",
        "        # Don't use BatchNorm in first layer!\n",
        "\n",
        "        # Block 2: (64, 32, 32) -> (128, 16, 16)\n",
        "        # Remember BatchNorm here\n",
        "\n",
        "        # Block 3: (128, 16, 16) -> (256, 8, 8)\n",
        "\n",
        "        # Block 4: (256, 8, 8) -> (512, 4, 4)\n",
        "\n",
        "        # Final: Flatten and Dense to single output\n",
        "        # Don't forget Sigmoid()!"
      ],
      "metadata": {
        "id": "eewhlwj4aKyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        self.block4 = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        self.output = nn.Sequential(\n",
        "            nn.Linear(512*4*4, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = x.view(-1, 512*4*4)  # flatten\n",
        "        x = self.output(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Nuj0oOtxj-BE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(real_images, generator, discriminator, criterion,\n",
        "               optimizer_G, optimizer_D, latent_dim):\n",
        "    batch_size = real_images.size(0)\n",
        "\n",
        "    # 1. Train Discriminator\n",
        "    optimizer_D.zero_grad()\n",
        "\n",
        "    # 1a. Train on real batch\n",
        "    # Hint: Create labels for real images (all ones)\n",
        "    # Hint: Forward real images through D\n",
        "    # Hint: Calculate loss for real images\n",
        "\n",
        "    # 1b. Train on fake batch\n",
        "    # Hint: Generate noise z\n",
        "    # Hint: Generate fake images using G(z)\n",
        "    # Hint: Create labels for fake images (all zeros)\n",
        "    # Hint: Forward fake images through D\n",
        "    # Hint: Calculate loss for fake images\n",
        "\n",
        "    # 1c. Add both losses and update D\n",
        "    # Hint: d_loss = d_loss_real + d_loss_fake\n",
        "    # Hint: backward and step\n",
        "\n",
        "    # 2. Train Generator\n",
        "    optimizer_G.zero_grad()\n",
        "\n",
        "    # 2a. Since we updated D, perform another forward pass of fake images\n",
        "    # Hint: Use the SAME noise vector z\n",
        "    # Hint: But we want D to think these are real! So use real_labels\n",
        "\n",
        "    # 2b. Calculate G's loss based on D's output\n",
        "    # Hint: Calculate loss using criterion\n",
        "    # Hint: backward and step\n",
        "\n",
        "    return d_loss.item(), g_loss.item()"
      ],
      "metadata": {
        "id": "bERsOhGMaNSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3dJZ6-kmaNgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xDlJ7-31aNn4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}